# üìö Awesome Large Language Model Resources

A curated collection of resources, papers, tools, and insights on Large Language Models (LLMs) to supercharge your AI journey!

## Table of Contents
- [Foundational Concepts](#foundational-concepts)
- [Research Papers](#research-papers)
- [Tools & Projects](#tools--projects)
- [Advanced Topics](#advanced-topics)

## Foundational Concepts
- **[Prompt Engineering: A Core Skill for LLMs](https://www.youtube.com/watch?v=L2jnRk2GYwg)**  
  Learn the basics of prompt engineering and why it's a critical skill for interacting with LLMs effectively.
- **[In-Context Learning: How It Works](https://www.lakera.ai/blog/what-is-in-context-learning)**  
  A beginner-friendly explanation of how LLMs leverage in-context learning to adapt to tasks without retraining.

## Research Papers
- **[Large Language Models as Data Preprocessors](https://arxiv.org/pdf/2308.16361)**  
  Explores how LLMs can preprocess and clean data for enhanced model performance.
- **[Tree of Thoughts: Deliberate Problem Solving with LLMs](https://arxiv.org/pdf/2305.10601)**  
  Introduces a novel approach to LLM reasoning through structured thought trees.
- **[Chain-of-Table: Evolving Tables in LLM Reasoning](https://arxiv.org/pdf/2401.04398)**  
  A framework for table-based reasoning to improve LLM understanding of structured data.
- **[LLMLingua: Compressing Prompts for Faster Inference](https://arxiv.org/pdf/2310.05736)**  
  Techniques to optimize prompts for efficient LLM inference.
- **[Everything of Thoughts](https://arxiv.org/pdf/2311.04254)**  
  A comprehensive approach to integrating thought processes in LLMs for complex tasks.
- **[Quantifying Language Models‚Äô Sensitivity](https://arxiv.org/pdf/2310.11324)**  
  Analyzes how LLMs respond to input variations and their robustness.
- **[Scalable Extraction of Training Data from LLMs](https://arxiv.org/abs/2311.17035)**  
  Methods to extract training data from production-grade LLMs.
- **[A Study of Fairness Concerns in AI-Based Mobile App Reviews](https://arxiv.org/html/2401.08097v2)**  
  Examines fairness issues in AI-driven mobile app review systems.

## Tools & Projects
- **[LLMLingua on Hugging Face](https://huggingface.co/spaces/microsoft/LLMLingua)**  
  Interactive space to experiment with LLMLingua‚Äôs prompt compression tools.
- **[LLMLingua GitHub Repository](https://github.com/microsoft/LLMLingua)**  
  Source code and documentation for the LLMLingua project.
- **[Everything of Thoughts GitHub](https://github.com/microsoft/Everything-of-Thoughts-XoT)**  
  Explore the code behind the Everything of Thoughts framework.
- **[Transluce Model Investigator](https://monitor.transluce.org/)**  
  A tool to debug and analyze LLM behavior for transparency.
- **[Uncensor Any LLM with Abliteration](https://huggingface.co/blog/mlabonne/abliteration#uncensor-any-llm-with-abliteration)**  
  A guide to removing censorship from LLMs using abliteration techniques.

## Advanced Topics
- **[Insecure Plugins for LLMs](https://learn.snyk.io/lesson/llm-insecure-plugins/?ecosystem=aiml)**  
  Insights into security risks associated with LLM plugins.
- **[Real-World Gender Bias in Language Models](https://lm-bias.lingvis.io/)**  
  Investigates how societal biases manifest in LLM outputs.
- **[Extracting Training Data from ChatGPT](https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html)**  
  Techniques and implications of extracting data from ChatGPT.
- **[Open-Ended GPT-2 Text Generation Explanations](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/text_generation/Open%20Ended%20GPT2%20Text%20Generation%20Explanations.html)**  
  Explains how GPT-2 generates open-ended text with SHAP analysis.
- **[Universal and Transferable Adversarial Attacks on LLMs](https://llm-attacks.org/index.html#examples)**  
  Explores vulnerabilities in aligned LLMs to adversarial attacks.

---

‚≠ê **Star this repo** if you find these resources helpful!  
üì¢ Contributions and suggestions for more LLM resources are welcome!